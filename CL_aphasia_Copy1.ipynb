{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "CL_aphasia-Copy1.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lightsamurai/API/blob/master/CL_aphasia_Copy1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKaF-StnnpnK"
      },
      "source": [
        "# APHASIC patients' linguistic production DIAGNOSIS with WORD2VEC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjFAMXTnnpnU"
      },
      "source": [
        "Aim of this work is to rank the severeness of the aphasia by applying Word2Vec tasks to our corpus, which was collected from the Aphasia Bank online database (https://aphasia.talkbank.org/). Here are collected transcriptions of aphasic patients' productions, spoken by accomplishing specific and standardized tasks of the Aphasia Bank Protocol (i.e. to describe the scene portraited in a picture the interviewer shows the patient). Word2vec uses a neural network model to learn word associations from a large corpus of text.\n",
        "\n",
        "We collected our input data of 2 lists of word pairs from the Aphasia Bank online database. The first list contains ˜100 EN target/response word pairs, where the target is the word which describes the scene (e.g. \"ball\") and the response is the word the patient produces (e.g. \"sphere\"). The second list contains ˜30 IT target/response word pairs.\n",
        "\n",
        "The semantic model we used to get the vector representations of our target/response English words are the pre-trained 'word2vec-google-news-300' vectors. To run the cosine similarity task we are using the built-in wv.similarity function of Word2Vec, which takes as input our word pairs and gives as output their cosine similarity. To accomplish the same task for our Italian word pairs we trained a model with the SkipGram algorithm of Word2Vec basing on 10 million word from Wikipedia using plainstream.\n",
        "\n",
        "We then looked for the most similar target/response word in our lists to get a severeness ranking for the aphasic patient's. We then look for the \"most similar\" words of the most common words in our databases (i.e. \"ball\") and see if among our response words we'll find some of the \"most similar\" words according to our models.\n",
        "\n",
        "Further steps (in progress):\n",
        "\n",
        "_give each word in our target/response lists a difficulty ranking, expressed with a float and basing on the lenght of the word. This difficulty evaluation (basing on the word lenght) will normally used by logopedists or in medical context dealing with language impairment. We'll then compute a correlation between the target/response word cosine similarity and the difficulty ranking of the target word. By doing that, we'll get a \"reweighting\" of how good the patient accomplished the task, considering also the difficulty of retrieving the target word\n",
        "\n",
        "_look if our target/response word is present in MEN database (any order the couple shows up) and if yes, compare the cosine similarity we got from the model for our word pairs and their similarity evaluated by human annotators"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YC5p1xQnpnX",
        "outputId": "8fed1916-e8f5-4ccc-a0a5-59ae1bf32b00"
      },
      "source": [
        "# First, I import our English input data and give a look inside the list of word pairs\n",
        "# I save our pairs as .csv file, i.e. comma separated value\n",
        "\n",
        "import pandas as pd\n",
        "import numpy\n",
        "\n",
        "# Create a dataframe from csv\n",
        "df = pd.read_csv(\"/Users/silviafabbi/Desktop/input_pairs_EN.csv\", \"r\", delimiter=',', engine='python')\n",
        "\n",
        "# User list comprehension to create a list of lists from Dataframe rows\n",
        "list_of_rows = [list(row) for row in df.values]\n",
        "\n",
        "print(df)\n",
        "type(df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      ball    bound\n",
            "0     ball     bask\n",
            "1   window     womb\n",
            "2   broken   bottom\n",
            "3     word    money\n",
            "4     rain      run\n",
            "..     ...      ...\n",
            "91     age     days\n",
            "92     say      see\n",
            "93    foot     head\n",
            "94   woman      man\n",
            "95     put     foot\n",
            "\n",
            "[96 rows x 2 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAr-q-glnpnb"
      },
      "source": [
        "def tupleize(file):\n",
        "    output = [] # I initialize an array (=list)\n",
        "    with open(file, \"r\") as input: \n",
        "        # I open our file in read only modality\n",
        "        # .readline() method allows us to read our data line by line using the \\n char inside our data\n",
        "        # The iterator goes through the data\n",
        "        line = input.readline()\n",
        "        # I take the first line of our input\n",
        "        while line:\n",
        "                \n",
        "        # Whith \"while\" I set a condition for \"line\" for my iterator:\n",
        "        # As long as \"line\" variable cointains something (i.e. as long as my iterator finds a new line to go through),\n",
        "        # our algorithm applies .rstrip() to the line to cancel the \\n command\n",
        "        # By doing this, our list called \"output\" becomes a list of tuples with a number of objects equals to those elements which contain a \", \"\n",
        "        # We substitute the content of the line with \", \" as separator and append the \"cleaned\" line to our list \"output\"\n",
        "            nuple = tuple(line.rstrip().split(\", \"))\n",
        "            output.append(nuple)\n",
        "            line = input.readline();\n",
        "        # We continue cycling through our data\n",
        "        # When input.readline() doesn't find a line anymore, \"while\" condition is not satisfied anymore\n",
        "        # As a consequence, our output is an empty line and our cycle stops\n",
        "        \n",
        "\n",
        "    return output\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dDG0mDinpnd",
        "outputId": "ef8e39a9-126b-4831-8c48-dac36f1b495e"
      },
      "source": [
        "# We apply our function to our dataset to transform it in a list of tuples\n",
        "\n",
        "input_EN = tupleize(\"/Users/silviafabbi/Desktop/input_pairs_EN.csv\")\n",
        "\n",
        "print(input_EN)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('ball', 'bound'), ('ball', 'bask'), ('window', 'womb'), ('broken', 'bottom'), ('word', 'money'), ('rain', 'run'), ('dog', 'guy'), ('bark', 'biting'), ('cat', 'god'), ('girl', 'guy'), ('tree', 'train'), ('ball', 'bald'), ('ball', 'barn'), ('ball', 'banks'), ('king', 'cleans'), ('king', 'kins'), ('glass', 'grass'), ('woman', 'man'), ('somewhere', 'someone'), ('wear', 'words'), ('shoe', 'scene'), ('boy', 'man'), ('mother', 'wife'), ('school', 'cool'), ('girl', 'earl'), ('slipper', 'sipper'), ('lamp', 'lap'), ('umbrella', 'ball'), ('short', 'sort'), ('boy', 'boil'), ('woman', 'man'), ('fourth', 'force'), ('door', 'window'), ('glass', 'gas'), ('soaking', 'stoking'), ('ladder', 'window'), ('kick', 'cook'), ('window', 'door'), ('umbrella', 'comb'), ('umbrella', 'bread'), ('catch', 'kitchen'), ('soccer', 'sock'), ('mother', 'daughter'), ('lamp', 'lights'), ('give', 'gay'), ('rescue', 'like'), ('dog', 'door'), ('bark', 'talk'), ('kick', 'cook'), ('show', 'go'), ('both', 'bow'), ('cat', 'hat'), ('dog', 'boy'), ('cat', 'girl'), ('bark', 'call'), ('reach', 'crawl'), ('there', 'hairs'), ('ride', 'drive'), ('quite', 'white'), ('girl', 'boy'), ('grow', 'goes'), ('page', 'bar'), ('umbrella', 'black'), ('naughty', 'nasty'), ('walk', 'speak'), ('girl', 'woman'), ('ride', 'run'), ('cat', 'hat'), ('branch', 'window'), ('father', 'mother'), ('tree', 'try'), ('tree', 'far'), ('dog', 'fog'), ('ladder', 'water'), ('ladder', 'bottle'), ('truck', 'bottle'), ('truck', 'home'), ('fire', 'ocean'), ('tree', 'hospital'), ('bird', 'song'), ('daughters', 'girls'), ('maid', 'main'), ('woman', 'man'), ('that', 'dat'), ('foot', 'pit'), ('slipper', 'pitcher'), ('put', 'pit'), ('sisters', 'brothers'), ('boy', 'man'), ('hands', 'heads'), ('cry', 'try'), ('wheels', 'feels'), ('age', 'days'), ('say', 'see'), ('foot', 'head'), ('woman', 'man'), ('put', 'foot')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhOxNUURnpne",
        "outputId": "9a423204-b751-49b2-90ba-f204b4ea96dd"
      },
      "source": [
        "with open(\"input_pairs_X.csv\", \"w+\") as printout:\n",
        "    for i in input_EN:\n",
        "        words = tupleize((input_EN))\n",
        "        for x in words:\n",
        "            printout.write(tupleize(i))\n",
        "            printout.write(\"\\n\")\n",
        "            printout.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'list' object has no attribute 'items'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-b86292d4300b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"input_pairs_X.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w+\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mprintout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_EN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtupleize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_EN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mprintout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtupleize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'items'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2v5hzrMynpnh",
        "outputId": "7e4c1512-9c78-4f39-e344-47428db5ee9e"
      },
      "source": [
        "pat_EN = tupleize(\"/Users/silviafabbi/Desktop/pat_input_EN.csv\")\n",
        "\n",
        "print(pat_EN)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('1', 'ball', 'bound'), ('1', 'ball', 'bask'), ('1', 'window', 'womb'), ('1', 'broken', 'bottom'), ('1', 'word', 'money'), ('1', 'rain', 'run'), ('1', 'dog', 'guy'), ('1', 'bark', 'biting'), ('1', 'cat', 'god'), ('1', 'girl', 'guy'), ('1', 'tree', 'train'), ('1', 'ball', 'bald'), ('1', 'ball', 'barn'), ('1', 'ball', 'banks'), ('1', 'king', 'cleans'), ('1', 'king', 'kins'), ('1', 'glass', 'grass'), ('1', 'woman', 'man'), ('1', 'somewhere', 'someone'), ('1', 'wear', 'words'), ('1', 'shoe', 'scene'), ('2', 'boy', 'man'), ('2', 'mother', 'wife'), ('2', 'school', 'cool'), ('2', 'girl', 'earl'), ('2', 'slipper', 'sipper'), ('3', 'lamp', 'lap'), ('3', 'umbrella', 'ball'), ('3', 'short', 'sort'), ('4', 'boy', 'boil'), ('4', 'woman', 'man'), ('5', 'fourth', 'force'), ('5', 'door', 'window'), ('6', 'glass', 'gas'), ('6', 'soaking', 'stoking'), ('6', 'ladder', 'window'), ('7', 'kick', 'cook'), ('7', 'window', 'door'), ('7', 'umbrella', 'comb'), ('7', 'umbrella', 'bread'), ('7', 'umbrella', 'read'), ('7', 'catch', 'kitchen'), ('8', 'ball', 'bell'), ('8', 'soccer', 'sock'), ('8', 'mother', 'daughter'), ('9', 'lamp', 'lights'), ('9', 'give', 'gay'), ('9', 'rescue', 'like'), ('9', 'dog', 'door'), ('9', 'bark', 'talk'), ('10', 'kick', 'cook'), ('10', 'show', 'go'), ('10', 'kick', 'hit'), ('10', 'both', 'bow'), ('10', 'cat', 'hat'), ('10', 'dog', 'boy'), ('10', 'cat', 'girl'), ('10', 'bark', 'call'), ('10', 'reach', 'crawl'), ('10', 'there', 'hairs'), ('10', 'ride', 'drive'), ('10', 'quite', 'white'), ('10', 'girl', 'boy'), ('10', 'grow', 'goes'), ('11', 'page', 'bar'), ('11', 'umbrella', 'black'), ('11', 'naughty', 'nasty'), ('11', 'walk', 'speak'), ('11', 'girl', 'woman'), ('11', 'ride', 'run'), ('11', 'cat', 'hat'), ('11', 'branch', 'window'), ('11', 'father', 'mother'), ('11', 'tree', 'try'), ('11', 'tree', 'far'), ('11', 'dog', 'fog'), ('11', 'ladder', 'water'), ('11', 'ladder', 'bottle'), ('11', 'truck', 'bottle'), ('11', 'truck', 'home'), ('11', 'fire', 'ocean'), ('11', 'tree', 'hospital'), ('11', 'bird', 'song'), ('11', 'daughters', 'girls'), ('11', 'maid', 'main'), ('11', 'woman', 'man'), ('11', 'that', 'dat'), ('11', 'foot', 'pit'), ('11', 'slipper', 'pitcher'), ('11', 'put', 'pit'), ('11', 'sisters', 'brothers'), ('12', 'boy', 'man'), ('12', 'hands', 'heads'), ('12', 'cry', 'try'), ('12', 'wheels', 'feels'), ('12', 'age', 'days'), ('12', 'say', 'see'), ('12', 'foot', 'head'), ('12', 'woman', 'man'), ('12', 'put', 'foot')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awyl3y0enpni",
        "outputId": "b89c50a2-a0e2-4c78-eef2-4212fe7b8005"
      },
      "source": [
        "def get_sim(data):\n",
        "    with open(\"list_of_.csv\", \"w\") as output:\n",
        "        \n",
        "        for w1, w2, w3 in data:\n",
        "            print('%r\\t%r\\t%.4f' % (w2, w3, wv.similarity(w2, w3)))\n",
        "            \n",
        "            output.write('%r\\t%r\\t%.4f' % (w2, w3, wv.similarity(w2, w3)))\n",
        "\n",
        "                    \n",
        "get_sim(pat_EN)\n",
        "\n",
        "output.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'ball'\t'bound'\t0.0339\n",
            "'ball'\t'bask'\t0.0549\n",
            "'window'\t'womb'\t0.1947\n",
            "'broken'\t'bottom'\t0.1166\n",
            "'word'\t'money'\t0.2119\n",
            "'rain'\t'run'\t0.1114\n",
            "'dog'\t'guy'\t0.2742\n",
            "'bark'\t'biting'\t0.3404\n",
            "'cat'\t'god'\t0.1099\n",
            "'girl'\t'guy'\t0.3644\n",
            "'tree'\t'train'\t0.1557\n",
            "'ball'\t'bald'\t0.1118\n",
            "'ball'\t'barn'\t0.0713\n",
            "'ball'\t'banks'\t0.0107\n",
            "'king'\t'cleans'\t0.0292\n",
            "'king'\t'kins'\t0.1493\n",
            "'glass'\t'grass'\t0.1117\n",
            "'woman'\t'man'\t0.7664\n",
            "'somewhere'\t'someone'\t0.4419\n",
            "'wear'\t'words'\t0.0561\n",
            "'shoe'\t'scene'\t0.0908\n",
            "'boy'\t'man'\t0.6825\n",
            "'mother'\t'wife'\t0.7551\n",
            "'school'\t'cool'\t0.1263\n",
            "'girl'\t'earl'\t0.2010\n",
            "'slipper'\t'sipper'\t0.1738\n",
            "'lamp'\t'lap'\t0.1483\n",
            "'umbrella'\t'ball'\t0.0570\n",
            "'short'\t'sort'\t0.1629\n",
            "'boy'\t'boil'\t0.1139\n",
            "'woman'\t'man'\t0.7664\n",
            "'fourth'\t'force'\t0.1147\n",
            "'door'\t'window'\t0.6213\n",
            "'glass'\t'gas'\t0.0585\n",
            "'soaking'\t'stoking'\t0.2246\n",
            "'ladder'\t'window'\t0.3029\n",
            "'kick'\t'cook'\t0.0898\n",
            "'window'\t'door'\t0.6213\n",
            "'umbrella'\t'comb'\t0.0946\n",
            "'umbrella'\t'bread'\t0.0462\n",
            "'umbrella'\t'read'\t-0.0125\n",
            "'catch'\t'kitchen'\t0.0604\n",
            "'ball'\t'bell'\t0.0863\n",
            "'soccer'\t'sock'\t0.1546\n",
            "'mother'\t'daughter'\t0.8706\n",
            "'lamp'\t'lights'\t0.4994\n",
            "'give'\t'gay'\t0.0486\n",
            "'rescue'\t'like'\t0.0662\n",
            "'dog'\t'door'\t0.1997\n",
            "'bark'\t'talk'\t0.1986\n",
            "'kick'\t'cook'\t0.0898\n",
            "'show'\t'go'\t0.1650\n",
            "'kick'\t'hit'\t0.2502\n",
            "'both'\t'bow'\t0.0941\n",
            "'cat'\t'hat'\t0.1706\n",
            "'dog'\t'boy'\t0.3522\n",
            "'cat'\t'girl'\t0.3039\n",
            "'bark'\t'call'\t0.1543\n",
            "'reach'\t'crawl'\t0.2543\n",
            "'there'\t'hairs'\t0.1014\n",
            "'ride'\t'drive'\t0.3714\n",
            "'quite'\t'white'\t0.0891\n",
            "'girl'\t'boy'\t0.8543\n",
            "'grow'\t'goes'\t0.1579\n",
            "'page'\t'bar'\t0.1206\n",
            "'umbrella'\t'black'\t0.1056\n",
            "'naughty'\t'nasty'\t0.4207\n",
            "'walk'\t'speak'\t0.2858\n",
            "'girl'\t'woman'\t0.7495\n",
            "'ride'\t'run'\t0.3192\n",
            "'cat'\t'hat'\t0.1706\n",
            "'branch'\t'window'\t0.2317\n",
            "'father'\t'mother'\t0.7901\n",
            "'tree'\t'try'\t0.0694\n",
            "'tree'\t'far'\t0.0678\n",
            "'dog'\t'fog'\t0.0666\n",
            "'ladder'\t'water'\t0.1233\n",
            "'ladder'\t'bottle'\t0.0927\n",
            "'truck'\t'bottle'\t0.1837\n",
            "'truck'\t'home'\t0.2014\n",
            "'fire'\t'ocean'\t0.0819\n",
            "'tree'\t'hospital'\t0.0841\n",
            "'bird'\t'song'\t0.1436\n",
            "'daughters'\t'girls'\t0.4398\n",
            "'maid'\t'main'\t0.0134\n",
            "'woman'\t'man'\t0.7664\n",
            "'that'\t'dat'\t0.1025\n",
            "'foot'\t'pit'\t0.0751\n",
            "'slipper'\t'pitcher'\t0.0831\n",
            "'put'\t'pit'\t0.0629\n",
            "'sisters'\t'brothers'\t0.6871\n",
            "'boy'\t'man'\t0.6825\n",
            "'hands'\t'heads'\t0.3448\n",
            "'cry'\t'try'\t0.1564\n",
            "'wheels'\t'feels'\t0.1272\n",
            "'age'\t'days'\t0.2333\n",
            "'say'\t'see'\t0.4852\n",
            "'foot'\t'head'\t0.0673\n",
            "'woman'\t'man'\t0.7664\n",
            "'put'\t'foot'\t0.1940\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'output' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-4e750b17b19f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mget_sim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpat_EN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'output' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPQXs5Ufnpnk"
      },
      "source": [
        "# Now we can transform every word in our dataset in a vector using KeyedVectors data from gensim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0sYW2HSnpnl"
      },
      "source": [
        "# MODEL 1 - EN - vectors from GoogleNews\n",
        "\n",
        "# We use gensim to import a word2vec model pretrained on Google News \n",
        "# We load the pretrained model of the type #gensim.models.keyedvectors.Word2VecKeyedVectors\n",
        "# using the gensim standard method .load()\n",
        "\n",
        "# This type of pretrained model cannot be refined with additional data: KeyedVectors it's an immutable model\n",
        "# but has the advantage of saving RAM by dealing with huge quantity of data\n",
        "# The 'word2vec-google-news-300' are pre-trained vectors trained on Google News dataset (about 100 billion words)\n",
        "# The model contains 300-dimensional vectors for 3 million words and phrases\n",
        "\n",
        "from gensim.models import Word2Vec\n",
        "import gensim.downloader as api"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVpBOjXQnpnm",
        "outputId": "2ea34850-bef9-4e28-9120-8eacf56fbdee"
      },
      "source": [
        "# I load my KeyedVectors based on GoogleNews\n",
        "# This will be the vector representation of the ca. 100 English words we collected from the AphasiaBank corpus\n",
        "\n",
        "wv = api.load('word2vec-google-news-300')\n",
        "type(wv) # gensim.models.keyedvectors.Word2VecKeyedVectors"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "gensim.models.keyedvectors.Word2VecKeyedVectors"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETh5xYPFnpnq",
        "outputId": "0abab915-7937-4d1f-dde5-d4cd33f2df0a"
      },
      "source": [
        "# We're going to compare the semantic similarity of the target/response word pairs\n",
        "# using wv = api.load('word2vec-google-news-300') as our pretrained model\n",
        "# input_EN = my list of tuples made by target/response word\n",
        "\n",
        "for w1, w2 in input_EN:\n",
        "    print('%r\\t%r\\t%.4f' % (w1, w2, wv.similarity(w1, w2)))\n",
        "    \n",
        "    \n",
        "# The last line of the code means following:    \n",
        "# \"%r\\t%r\\t\" are like \"jolly\" charachters, which will be substituted with the content of out n-uple which went through \"%\"\n",
        "# Here we have a \"%r\" string, followed by tabulation \"\\t\", followed my another string \"%r\" and \"\\t\"\n",
        "# \"% .4f\" closes with a float with 4 numbers after the \",\"\n",
        "# Python knows it shall substitute - in the specified order - those sequences (strings/tabulation)\n",
        "# with the content of the variables which went trough \"%\" before printing them\n",
        "# The % symbol in Python is called the Modulo Operator\n",
        "# It returns the remainder of dividing the left hand operand by right hand operand\n",
        "# It's used to get the remainder of a division problem"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'ball'\t'bound'\t0.0339\n",
            "'ball'\t'bask'\t0.0549\n",
            "'window'\t'womb'\t0.1947\n",
            "'broken'\t'bottom'\t0.1166\n",
            "'word'\t'money'\t0.2119\n",
            "'rain'\t'run'\t0.1114\n",
            "'dog'\t'guy'\t0.2742\n",
            "'bark'\t'biting'\t0.3404\n",
            "'cat'\t'god'\t0.1099\n",
            "'girl'\t'guy'\t0.3644\n",
            "'tree'\t'train'\t0.1557\n",
            "'ball'\t'bald'\t0.1118\n",
            "'ball'\t'barn'\t0.0713\n",
            "'ball'\t'banks'\t0.0107\n",
            "'king'\t'cleans'\t0.0292\n",
            "'king'\t'kins'\t0.1493\n",
            "'glass'\t'grass'\t0.1117\n",
            "'woman'\t'man'\t0.7664\n",
            "'somewhere'\t'someone'\t0.4419\n",
            "'wear'\t'words'\t0.0561\n",
            "'shoe'\t'scene'\t0.0908\n",
            "'boy'\t'man'\t0.6825\n",
            "'mother'\t'wife'\t0.7551\n",
            "'school'\t'cool'\t0.1263\n",
            "'girl'\t'earl'\t0.2010\n",
            "'slipper'\t'sipper'\t0.1738\n",
            "'lamp'\t'lap'\t0.1483\n",
            "'umbrella'\t'ball'\t0.0570\n",
            "'short'\t'sort'\t0.1629\n",
            "'boy'\t'boil'\t0.1139\n",
            "'woman'\t'man'\t0.7664\n",
            "'fourth'\t'force'\t0.1147\n",
            "'door'\t'window'\t0.6213\n",
            "'glass'\t'gas'\t0.0585\n",
            "'soaking'\t'stoking'\t0.2246\n",
            "'ladder'\t'window'\t0.3029\n",
            "'kick'\t'cook'\t0.0898\n",
            "'window'\t'door'\t0.6213\n",
            "'umbrella'\t'comb'\t0.0946\n",
            "'umbrella'\t'bread'\t0.0462\n",
            "'catch'\t'kitchen'\t0.0604\n",
            "'soccer'\t'sock'\t0.1546\n",
            "'mother'\t'daughter'\t0.8706\n",
            "'lamp'\t'lights'\t0.4994\n",
            "'give'\t'gay'\t0.0486\n",
            "'rescue'\t'like'\t0.0662\n",
            "'dog'\t'door'\t0.1997\n",
            "'bark'\t'talk'\t0.1986\n",
            "'kick'\t'cook'\t0.0898\n",
            "'show'\t'go'\t0.1650\n",
            "'both'\t'bow'\t0.0941\n",
            "'cat'\t'hat'\t0.1706\n",
            "'dog'\t'boy'\t0.3522\n",
            "'cat'\t'girl'\t0.3039\n",
            "'bark'\t'call'\t0.1543\n",
            "'reach'\t'crawl'\t0.2543\n",
            "'there'\t'hairs'\t0.1014\n",
            "'ride'\t'drive'\t0.3714\n",
            "'quite'\t'white'\t0.0891\n",
            "'girl'\t'boy'\t0.8543\n",
            "'grow'\t'goes'\t0.1579\n",
            "'page'\t'bar'\t0.1206\n",
            "'umbrella'\t'black'\t0.1056\n",
            "'naughty'\t'nasty'\t0.4207\n",
            "'walk'\t'speak'\t0.2858\n",
            "'girl'\t'woman'\t0.7495\n",
            "'ride'\t'run'\t0.3192\n",
            "'cat'\t'hat'\t0.1706\n",
            "'branch'\t'window'\t0.2317\n",
            "'father'\t'mother'\t0.7901\n",
            "'tree'\t'try'\t0.0694\n",
            "'tree'\t'far'\t0.0678\n",
            "'dog'\t'fog'\t0.0666\n",
            "'ladder'\t'water'\t0.1233\n",
            "'ladder'\t'bottle'\t0.0927\n",
            "'truck'\t'bottle'\t0.1837\n",
            "'truck'\t'home'\t0.2014\n",
            "'fire'\t'ocean'\t0.0819\n",
            "'tree'\t'hospital'\t0.0841\n",
            "'bird'\t'song'\t0.1436\n",
            "'daughters'\t'girls'\t0.4398\n",
            "'maid'\t'main'\t0.0134\n",
            "'woman'\t'man'\t0.7664\n",
            "'that'\t'dat'\t0.1025\n",
            "'foot'\t'pit'\t0.0751\n",
            "'slipper'\t'pitcher'\t0.0831\n",
            "'put'\t'pit'\t0.0629\n",
            "'sisters'\t'brothers'\t0.6871\n",
            "'boy'\t'man'\t0.6825\n",
            "'hands'\t'heads'\t0.3448\n",
            "'cry'\t'try'\t0.1564\n",
            "'wheels'\t'feels'\t0.1272\n",
            "'age'\t'days'\t0.2333\n",
            "'say'\t'see'\t0.4852\n",
            "'foot'\t'head'\t0.0673\n",
            "'woman'\t'man'\t0.7664\n",
            "'put'\t'foot'\t0.1940\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1l-A_ZjHnpnr",
        "outputId": "2181f7d9-0f69-4d55-df78-66b02b66ffb3"
      },
      "source": [
        "wv.most_similar(\"ball\", topn=20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('balls', 0.6992625594139099),\n",
              " ('upfield', 0.6896207928657532),\n",
              " ('downfield', 0.6390728950500488),\n",
              " ('dribbler', 0.6218727827072144),\n",
              " ('balll', 0.6199932098388672),\n",
              " ('dribble', 0.616877555847168),\n",
              " ('ball_squirted', 0.6110137701034546),\n",
              " ('leftfooted', 0.6020259857177734),\n",
              " ('puck', 0.5981724262237549),\n",
              " ('mishit', 0.5948782563209534),\n",
              " ('lofted', 0.5933606028556824),\n",
              " ('theball', 0.5924203395843506),\n",
              " ('bobbling', 0.5848650336265564),\n",
              " ('dinked', 0.5820186138153076),\n",
              " ('dribbles', 0.5811805725097656),\n",
              " ('beautifully_flighted', 0.5757741928100586),\n",
              " ('mistimes', 0.5747321844100952),\n",
              " ('onsides', 0.5730898380279541),\n",
              " ('perfectly_flighted', 0.5724466443061829),\n",
              " ('deadball', 0.5708563923835754)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0YU5dl6npnt"
      },
      "source": [
        "For \"ball\" we have in our input pairs following matches: {(ball, bound), (ball, bask), (ball, bald), (ball, barn),(ball, banks), (umbrella, ball)} -> none of them shows up as a result of the \"most similar\" for Google vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43jvJvPanpnu"
      },
      "source": [
        "# MODEL 2 - IT - vectors from a model from plainstream/wikipedia\n",
        "# model ITA from Wikipedia - 10 mln words\n",
        "# \n",
        "# After training a w2v model in ITA, we saved it as a .model file\n",
        "# The model was trained using the Skip Gram algorithm of Word2Vec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zLBsK1dnpnv"
      },
      "source": [
        "import nltk\n",
        "import plainstream\n",
        "import gensim\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "# We are introducing the time module: it has many uses, but here we are just using the .time() method\n",
        "# to measure the execution time of a process\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbys8ch_npnw"
      },
      "source": [
        "some_wiki # <generator object get_text at 0x7fce21e0ac10>"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFhRDXIknpnw"
      },
      "source": [
        "s = time.time()\n",
        "# Here we are asking plainstream to give us a certain amount of words (10 milion in this case)\n",
        "# NB: a plainstream.get_text() obejct is a generator, which is empty after one use\n",
        "# Generator functions allow you to declare a function that behaves like an iterator\n",
        "# i.e. it can be used in a for loop\n",
        "some_wiki = plainstream.get_text(\"it\", max_words=10000000, tokenize=True)\n",
        "some_text = []\n",
        "\n",
        "# we want to make sure that every word is lower case. Because some_wiki generates lists\n",
        "# of lists of tokens (i.e: tokenized sentences) we need to nest a couple of for loops in order to \n",
        "# reach the strings that we want to manipulate\n",
        "\n",
        "for tokens_list in some_wiki:\n",
        "    temp = []\n",
        "    for word in tokens_list:\n",
        "        temp.append(word.lower())\n",
        "    some_text.append(temp)\n",
        "e = time.time()\n",
        "print(e-s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DyFzme36npnw"
      },
      "source": [
        "s = time.time()\n",
        "# this is where we train the model. We are using a couple of parameters here, but the most\n",
        "# relevant is \"sg\", which means that we are using the skipgram algorithm\n",
        "model_ita = gensim.models.word2vec.Word2Vec(sentences=some_text, size=300, min_count=4, sg=1)\n",
        "e = time.time()\n",
        "print(e-s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8tHBSjEnpnx"
      },
      "source": [
        "# we save our model\n",
        "\n",
        "model_ita.save(\"/Users/silviafabbi/Desktop/ord2vec_10mil_wiki.model\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOJz2XNInpnz"
      },
      "source": [
        "# reload the trained model\n",
        "\n",
        "model_ita = KeyedVectors.load(\"/Users/silviafabbi/Desktop/ord2vec_10mil_wiki.model\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvsI6LCnnpn7",
        "outputId": "5e95f013-51ec-4d07-dc2d-d04ba56326ae"
      },
      "source": [
        "coppie = tupleize(\"/Users/silviafabbi/Desktop/input_pairs_IT.csv\")\n",
        "coppie"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('abbaia', 'saluta'),\n",
              " ('scala', 'piede'),\n",
              " ('calciare', 'lanciare'),\n",
              " ('prendere', 'chiedere'),\n",
              " ('ombrello', 'acqua'),\n",
              " ('bagnato', 'dormire'),\n",
              " ('rincorrere', 'prendere'),\n",
              " ('abbaia', 'gioca'),\n",
              " ('vetro', 'vetro'),\n",
              " ('ombrello', 'pioggia'),\n",
              " ('palla', 'finestra'),\n",
              " ('rompere', 'venire'),\n",
              " ('prendere', 'mettere'),\n",
              " ('salvare', 'trascinare'),\n",
              " ('sorellastre', 'donne'),\n",
              " ('topi', 'scoiattoli'),\n",
              " ('fata', 'amante'),\n",
              " ('fata', 'aspetta'),\n",
              " ('fata', 'la'),\n",
              " ('piove', 'pioggia'),\n",
              " ('bloccare', 'restare'),\n",
              " ('figlie', 'sorelle'),\n",
              " ('scomparire', 'spegnere'),\n",
              " ('lanciare', 'fare'),\n",
              " ('uscire', 'partire'),\n",
              " ('palla', 'palo')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVMKN8WPnpn8",
        "outputId": "66b0180a-1991-471b-8fdd-1cb798b14c31"
      },
      "source": [
        "for w1, w2 in coppie:\n",
        "    print('%r\\t%r\\t%.4f' % (w1, w2, model_ita.wv.similarity(w1, w2)))\n",
        "    \n",
        "# in case the response word matches the target word (like \"pioggia\" vs \"pioggia\") the similarity is 1 (maximum)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'abbaia'\t'saluta'\t0.7050\n",
            "'scala'\t'piede'\t0.1823\n",
            "'calciare'\t'lanciare'\t0.5785\n",
            "'prendere'\t'chiedere'\t0.5782\n",
            "'ombrello'\t'acqua'\t0.4904\n",
            "'bagnato'\t'dormire'\t0.4128\n",
            "'rincorrere'\t'prendere'\t0.4610\n",
            "'abbaia'\t'gioca'\t0.4616\n",
            "'vetro'\t'vetro'\t1.0000\n",
            "'ombrello'\t'pioggia'\t0.4927\n",
            "'palla'\t'finestra'\t0.4999\n",
            "'rompere'\t'venire'\t0.4567\n",
            "'prendere'\t'mettere'\t0.5360\n",
            "'salvare'\t'trascinare'\t0.6874\n",
            "'sorellastre'\t'donne'\t0.4786\n",
            "'topi'\t'scoiattoli'\t0.6643\n",
            "'fata'\t'amante'\t0.5440\n",
            "'fata'\t'aspetta'\t0.5140\n",
            "'fata'\t'la'\t0.2890\n",
            "'piove'\t'pioggia'\t0.5240\n",
            "'bloccare'\t'restare'\t0.5101\n",
            "'figlie'\t'sorelle'\t0.8361\n",
            "'scomparire'\t'spegnere'\t0.6290\n",
            "'lanciare'\t'fare'\t0.4572\n",
            "'uscire'\t'partire'\t0.3452\n",
            "'palla'\t'palo'\t0.4779\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3N6sbZi0npoB",
        "outputId": "5a6153c4-0db0-4b8f-b4d4-fc8d987c32e4"
      },
      "source": [
        "model_ita.wv.most_similar(\"palla\", topn=20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('pallina', 0.7703580260276794),\n",
              " ('racchetta', 0.7295913696289062),\n",
              " ('boccia', 0.7282717227935791),\n",
              " ('pedina', 0.7159955501556396),\n",
              " ('buca', 0.7057750225067139),\n",
              " (\"all'indietro\", 0.7046733498573303),\n",
              " ('virata', 0.7045900821685791),\n",
              " ('scopa', 0.7014609575271606),\n",
              " (\"l'asta\", 0.6888625621795654),\n",
              " ('fallo', 0.6849193572998047),\n",
              " (\"l'avversario\", 0.6848279237747192),\n",
              " ('battitore', 0.6810046434402466),\n",
              " ('tira', 0.6789371967315674),\n",
              " ('polso', 0.6747191548347473),\n",
              " (\"sull'acqua\", 0.6742557883262634),\n",
              " (\"l'hammer\", 0.6721363067626953),\n",
              " ('avversaria', 0.6710895299911499),\n",
              " ('patta', 0.6709756255149841),\n",
              " ('capriola', 0.6647751331329346),\n",
              " ('alzata', 0.6643388271331787)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnP_0G99npoD"
      },
      "source": [
        "For \"palla\" we have in our input pairs following matches: {(palla, finestra), (palla, palo)} -> none of them shows up as a result of the \"most similar\" basing on our Wikipedia model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywkckoZDnpoE",
        "outputId": "2c8d569e-0c34-4873-e369-400f30d891db"
      },
      "source": [
        "# Let's now create the difficulty ranking for our italian pairs\n",
        "\n",
        "def main_it():\n",
        "    scores = []\n",
        "    max = 0\n",
        "\n",
        "    with open(\"/Users/silviafabbi/aphasia/test/data/italian.csv\", \"r\") as words:\n",
        "        word = words.readline()\n",
        "        while word:\n",
        "            word = word.rstrip() # rstrip cancels the new line\n",
        "            difficulty = len(word)\n",
        "            # Keep track of the maximum difficulty for this dataset\n",
        "            if max < difficulty:\n",
        "                max = difficulty\n",
        "\n",
        "            scores.append((word, difficulty))\n",
        "            word = words.readline();\n",
        "\n",
        "    print(\"Max score is: \" + str(max))\n",
        "\n",
        "    with open(\"/Users/silviafabbi/Desktop/difficulty_IT_x.csv\", \"w\") as diff:\n",
        "        for tuple in scores:\n",
        "            diff.write(\", \".join([tuple[0], str(tuple[1] / max)]))\n",
        "            diff.write(\"\\n\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main_it()\n",
        "else:\n",
        "    print(\"Not to be used as a module.\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max score is: 31\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2DaqWRVnpoH"
      },
      "source": [
        "# I want my difficulty list to become a dictionary (unordered list of tuples: key = word, value = difficulty)\n",
        "\n",
        "def tupleize(file):\n",
        "    output = [] # inizalizzo un array\n",
        "    with open(file, \"r\") as input: # file è path aperto in modalità read only, prendo prima linea\n",
        "        # finché c'è dentro line qualcosa, applico rstrip per togliere il comando \\n\n",
        "        # line pulita viene splittata dal marcatore , spazio - torna un array (da tupla) di oggetti tanti quanti sono oggetti demarcati da virgola spazio\n",
        "        # non vogliamo un array, vogliamo una tupla\n",
        "        # array = set = list(python)\n",
        "        # nuple è una tupla e aggiungo una lista di tuple\n",
        "        # infine legge linea dopo e torna all'inizio\n",
        "        # quando ha input.realine() vuota e while non è soddisfatto torna lista vuota fine esecuzione\n",
        "        \n",
        "        line = input.readline()\n",
        "        while line:\n",
        "            nuple = tuple(line.rstrip().split(\", \"))\n",
        "            output.append(nuple)\n",
        "            line = input.readline();\n",
        "\n",
        "    return output\n",
        "\n",
        "difficulty = dict(tupleize(\"/Users/silviafabbi/Desktop/difficulty_IT_x.csv\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdA-lZk8npoI",
        "outputId": "8903ec5d-ee2d-4431-d662-a2549b23fa16"
      },
      "source": [
        "# lines = difficulty.readlines()\n",
        "\n",
        "# I want to correlate my SIMILARITY_CHART_IT (made of tuples = w1, w2, cos_sim)\n",
        "# with the difficulty = DIFFICULTY_IT_x.CSV (made of tuples = w, difficulty_score)\n",
        "\n",
        "# I have to give w1, w2 a difficulty score\n",
        "\n",
        "def diff_rank():\n",
        "    diff = [] # I initialize my list of tuples = target word + correlation btw cos_sim and difficulty\n",
        "    max = 0\n",
        "    for i in lines:\n",
        "        if word in difficulty:\n",
        "            with open(\"/Users/silviafabbi/Desktop/mean_IT_x.csv\", \"w\") as diff:\n",
        "                for i in lines:\n",
        "                    diff.write(\", \".join([tuple[0], str(tuple[1] / max)]))\n",
        "                    diff.write(\"\\n\")\n",
        "                    diff.close()\n",
        "                    \n",
        "if __name__ == \"__diff_rank__\":\n",
        "    diff_rank()\n",
        "else:\n",
        "    print(\"No way!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No way!\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}